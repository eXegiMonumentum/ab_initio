"""
1Ô∏è‚É£ Nagrywanie danych (gesture_record.py)
2Ô∏è‚É£ Przygotowanie danych (prepare_gesture_data.py)
3Ô∏è‚É£ Trening modelu (train_gesture_lstm.py)
4Ô∏è‚É£ Ewaluacja modelu (evaluate_model.py)
5Ô∏è‚É£ Rozpoznawanie gest√≥w na ≈ºywo z kamery (predict_live.py)
"""

"""
Skrypt wczytuje pliki CSV z folderu gestures_data, przetwarza je do postaci
macierzy NumPy gotowych do trenowania modelu uczenia maszynowego (np. LSTM).

Ka≈ºdy gest jest reprezentowany jako sekwencja 21 punkt√≥w 3D (x, y, z) na ka≈ºdƒÖ klatkƒô.
Skrypt interpoluje ka≈ºdƒÖ sekwencjƒô do sta≈Çej liczby klatek (np. 100) i normalizuje dane.

Zwraca dwie tablice NumPy:
- X: dane wej≈õciowe, kszta≈Çt (num_samples, target_frames, 63)
- y: etykiety gest√≥w (0, 1, ...)

"""

import os
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from scipy.interpolate import interp1d

# G≈Ç√≥wny katalog z danymi
output_dir = "gestures_data"

def load_gesture_data(gesture_name, label, target_frames=100):
    """
    Wczytuje i przetwarza dane z plik√≥w CSV danego gestu.
    Ka≈ºdy plik jest interpolowany do sta≈Çej liczby klatek i normalizowany.

    Zwraca: lista (sequence, label)
    """
    gesture_dir = os.path.join(output_dir, gesture_name)
    files = [f for f in os.listdir(gesture_dir) if f.endswith("_positions.csv")]

    data_list = []

    for file in files:
        csv_path = os.path.join(gesture_dir, file)
        df = pd.read_csv(csv_path, names=["frame", "x", "y", "z", "hand"])

        # Grupowanie po klatkach i wybieranie tylko jednej d≈Çoni (najczƒô≈õciej prawej)
        hand_to_use = df["hand"].mode()[0]  # najczƒôstsza warto≈õƒá
        df = df[df["hand"] == hand_to_use]  # filtruj tylko wybranƒÖ d≈Ço≈Ñ

        frames = []
        for frame_id, group in df.groupby("frame"):
            coords = group[["x", "y", "z"]].values.flatten()
            if len(coords) == 63:
                frames.append(coords)

        if len(frames) < 10:
            continue  # pomi≈Ñ zbyt kr√≥tkie sekwencje

        frames = np.array(frames)

        # Interpolacja do jednakowej liczby klatek
        interp_frames = []
        for i in range(frames.shape[1]):
            interp_func = interp1d(np.linspace(0, 1, len(frames)), frames[:, i], kind="linear")
            interp_col = interp_func(np.linspace(0, 1, target_frames))
            interp_frames.append(interp_col)

        interp_sequence = np.stack(interp_frames, axis=1)  # shape = (target_frames, 63)
        data_list.append((interp_sequence, label))

    return data_list

# === Definicja etykiet gest√≥w ===
if __name__ == "__main__":
    gestures = {
        "shake": 0,
        "wave": 1,
        "stop": 2,
        "wave_both": 3,
        "freeze": 4,
        "wiggle_V": 5,
        "shake_sidechains": 6,
        "rebuild": 7,
        "zoom_in": 8,
        "zoom_out": 9,
    }

    dataset = []
    for gesture, label in gestures.items():
        dataset.extend(load_gesture_data(gesture, label))

    # === Przygotowanie danych ===
    X = np.array([seq for seq, _ in dataset])
    y = np.array([lbl for _, lbl in dataset])

    # === Normalizacja danych ===
    scaler = StandardScaler()
    X = np.array([scaler.fit_transform(seq) for seq in X])

    print(f"‚úÖ Przygotowano {len(X)} przyk≈Çad√≥w, shape: {X.shape}, etykiety: {set(y)}")


    # === Zapisz dane do plik√≥w .npy ===
    np.save("X_gestures.npy", X)
    np.save("y_gestures.npy", y)
    print("üíæ Dane zapisane jako X_gestures.npy i y_gestures.npy")

    # === Animowana wizualizacja 3D ca≈Çej d≈Çoni ===
    import matplotlib.pyplot as plt
    from mpl_toolkits.mplot3d import Axes3D
    from matplotlib.animation import FuncAnimation

    sample = X[0]  # Pierwsza sekwencja (target_frames, 63)

    # Przygotuj dane jako 21 punkt√≥w (x, y, z) na ka≈ºdƒÖ klatkƒô
    points_per_frame = sample.reshape(-1, 21, 3)  # shape = (target_frames, 21, 3)

    fig = plt.figure(figsize=(8, 6))
    ax = fig.add_subplot(111, projection='3d')
    sc = ax.scatter([], [], [], c='red', s=40)

    # Ustawienia osi
    ax.set_xlim([-2, 2])
    ax.set_ylim([-2, 2])
    ax.set_zlim([-2, 2])
    ax.set_xlabel("X")
    ax.set_ylabel("Y")
    ax.set_zlabel("Z")
    ax.set_title("üñê Animacja 3D trajektorii d≈Çoni")

    def update(frame_idx):
        coords = points_per_frame[frame_idx]
        sc._offsets3d = (coords[:, 0], coords[:, 1], coords[:, 2])
        return sc,

    ani = FuncAnimation(fig, update, frames=len(points_per_frame), interval=100, blit=False)
    plt.show()



# 2. Przygotowanie danych ‚Äì prepare_gesture_data.py
# Wczytuje dane CSV z wielu plik√≥w i gest√≥w.
# Dla ka≈ºdej klatki tworzy 63-wymiarowy wektor: 21 punkt√≥w √ó 3 wsp√≥≈Çrzƒôdne.
# Interpoluje ka≈ºdƒÖ pr√≥bkƒô do tej samej d≈Çugo≈õci (np. 100 klatek).
# Normalizuje dane (standaryzacja).

# Zapisuje dane do .npy:
# X_gestures.npy, y_gestures.npy

# dane .npy przyjmuje plik train_gesture_lstm.py
