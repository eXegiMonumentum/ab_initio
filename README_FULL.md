# ğŸ– Real-Time Hand Gesture Recognition System  
> Kamera OAK-D + MediaPipe + PyTorch LSTM  
> Autorzy: *[PojawiÄ… siÄ™ :D]*  
> Status: ğŸš€ Stabilny / w ciÄ…gÅ‚ym rozwoju

## ğŸ§  O projekcie

System rozpoznawania gestÃ³w dÅ‚oni w czasie rzeczywistym, oparty na:
- detekcji punktÃ³w dÅ‚oni (MediaPipe),
- nagrywaniu i przygotowywaniu danych gestÃ³w (OAK-D),
- trenowaniu modelu LSTM (PyTorch),
- rozpoznawaniu gestÃ³w na Å¼ywo z kamery.

System moÅ¼e byÄ‡ wykorzystywany do sterowania aplikacjami, interfejsami uÅ¼ytkownika, w Å›rodowiskach VR/AR, lub jako rozwiÄ…zanie dla systemÃ³w embedded.

## ğŸ¯ GÅ‚Ã³wne funkcje

âœ… Nagrywanie wÅ‚asnych gestÃ³w z kamery OAK-D  
âœ… Detekcja i podpisywanie dÅ‚oni ("Left/Right")  
âœ… Eksport danych do CSV + nagrania RGB/Depth AVI  
âœ… Automatyczna interpolacja, normalizacja i konwersja do `.npy`  
âœ… Trenowanie modelu LSTM do klasyfikacji gestÃ³w  
âœ… Ewaluacja modelu  
âœ… Rozpoznawanie gestÃ³w na Å¼ywo z buforem 100 klatek

## ğŸ“ Struktura projektu

```bash
ğŸ“¦ gesture-recognition
â”œâ”€â”€ gestures_data/           # ğŸ“‚ Nagrania i dane gestÃ³w
â”‚   â”œâ”€â”€ shake/
â”‚   â”‚   â”œâ”€â”€ shake_01_positions.csv
â”‚   â”‚   â”œâ”€â”€ shake_rgb.avi
â”‚   â”‚   â””â”€â”€ shake_depth.avi
â”‚   â””â”€â”€ wave/
â”‚       â””â”€â”€ ...
â”œâ”€â”€ gesture_record.py        # ğŸ¥ Nagrywanie gestÃ³w z kamery
â”œâ”€â”€ prepare_gesture_data.py  # ğŸ§¹ Przetwarzanie CSV do formatu sieci
â”œâ”€â”€ train_gesture_lstm.py    # ğŸ§  Trenowanie modelu LSTM
â”œâ”€â”€ evaluate_model.py        # ğŸ“Š Ocena skutecznoÅ›ci
â”œâ”€â”€ predict_live.py          # ğŸš€ Rozpoznawanie gestÃ³w na Å¼ywo
â”œâ”€â”€ gesture_record_help.py   # ğŸ§° Funkcje pomocnicze
â”œâ”€â”€ X_gestures.npy           # ğŸ’¾ Dane wejÅ›ciowe (sekwencje)
â”œâ”€â”€ y_gestures.npy           # ğŸ’¾ Etykiety (klasy gestÃ³w)
â”œâ”€â”€ gesture_model.pt         # ğŸ§  Wytrenowany model PyTorch
â””â”€â”€ README.md                # ğŸ“„ Ten plik
```

## ğŸ” Pipeline (przepÅ‚yw pracy)

1. **[1] `gesture_record.py`**  
   ğŸ‘‰ Nagrywaj wÅ‚asne gesty â€“ kamera OAK-D, MediaPipe, CSV, RGB + Depth.

2. **[2] `prepare_gesture_data.py`**  
   ğŸ‘‰ Interpoluj dane, normalizuj, konwertuj do `.npy` (X, y).

3. **[3] `train_gesture_lstm.py`**  
   ğŸ‘‰ Trenuj model LSTM na przygotowanych danych.

4. **[4] `evaluate_model.py`**  
   ğŸ‘‰ SprawdÅº skutecznoÅ›Ä‡ modelu.

5. **[5] `predict_live.py`**  
   ğŸ‘‰ WÅ‚Ä…cz rozpoznawanie gestÃ³w w czasie rzeczywistym!

## ğŸ§© ObsÅ‚ugiwane gesty

| Gest | Klasa |
|------|--------|
| `shake` | 0 |
| `wave` | 1 |
| `stop` | 2 |
| `wave_both` | 3 |
| `freeze` | 4 |
| `wiggle_V` | 5 |
| `shake_sidechains` | 6 |
| `rebuild` | 7 |
| `zoom_in` | 8 |
| `zoom_out` | 9 |
 0 |
| `wave`  | 1 |
| `...`   | MoÅ¼esz dodawaÄ‡ kolejne! |

## ğŸ› ï¸ Wymagania

- Python 3.8+
- PyTorch
- DepthAI
- MediaPipe
- NumPy, OpenCV, Matplotlib, Scikit-learn

Instalacja (pip):
```bash
pip install torch opencv-python mediapipe numpy matplotlib scikit-learn
```

## ğŸ›£ï¸ Plany rozwoju

- [x] ObsÅ‚uga wielu gestÃ³w
- [ ] Rozpoznawanie obu dÅ‚oni jednoczeÅ›nie
- [ ] Sterowanie aplikacjami (Foldit, VR, GUI)
- [ ] Eksport do embedded/mobile (Raspberry Pi, Android)
- [ ] Integracja z Google VR i Å›rodowiskami 3D

## ğŸ§  Model

LSTM przyjmuje dane wejÅ›ciowe w formacie `(samples, 100 klatek, 63 wspÃ³Å‚rzÄ™dnych)`  
KaÅ¼da prÃ³bka zawiera 21 punktÃ³w dÅ‚oni Ã— 3 wspÃ³Å‚rzÄ™dne (x, y, z) na kaÅ¼dÄ… klatkÄ™.

## ğŸ–¼ï¸ PrzykÅ‚adowa animacja (prepare_gesture_data.py)

â¬†ï¸ Interpolowana trajektoria dÅ‚oni w 3D (**dodam grafikÄ™**)

## ğŸ§‘â€ğŸ’» Autorzy
    --> pojawiÄ… siÄ™ :D

Projekt stworzony z pasji. 
Zaprojektowany modularnie, gotowy na rozwÃ³j i deployment.

Masz pytania lub chcesz wspÃ³Å‚tworzyÄ‡?  
e-mail: 167128@stud.prz.edu.pl

lub zgÅ‚oÅ› siÄ™ przez GitHub! â­
